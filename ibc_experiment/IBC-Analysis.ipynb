{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/.local/lib/python3.8/site-packages/nilearn-0.8.1-py3.8.egg/nilearn/datasets/__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from nilearn import datasets, image, plotting\n",
    "from neurolang.frontend import NeurolangPDL\n",
    "\n",
    "import neurolang\n",
    "neurolang.config.disable_expression_type_printing()\n",
    "\n",
    "JULICH_REGIONS_PATH = 'JULICH_BRAIN_CYTOARCHITECTONIC_MAPS_2_9_MNI152_2009C_NONL_ASYM.txt'\n",
    "JULICH_ATLAS_PATH = 'JULICH_BRAIN_CYTOARCHITECTONIC_MAPS_2_9_MNI152_2009C_NONL_ASYM.pmaps.nii.gz'\n",
    "PEAKS_PATH = 'peaks_IBC.csv'\n",
    "\n",
    "julich = False\n",
    "RESAMPLE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mni_t1 = nib.load(datasets.fetch_icbm152_2009()['t1'])\n",
    "mni_t1_4mm = image.resample_img(mni_t1, np.eye(3) * RESAMPLE)\n",
    "\n",
    "if julich:\n",
    "\n",
    "    lines = []\n",
    "    with open(JULICH_REGIONS_PATH) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    count = 0\n",
    "    res = []\n",
    "    for line in lines:\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "            continue\n",
    "        splited = line.split(' ')\n",
    "        res.append((splited[0], ' '.join(splited[1:-1])[1:], splited[-1][:-2]))\n",
    "\n",
    "    regions = pd.DataFrame(res, columns=['r_number', 'r_name', 'hemis'])\n",
    "    regions = regions[~regions.r_name.str.contains('GapMap')]\n",
    "    regions = regions.astype({'r_number': 'int64'})\n",
    "    region_number = 'r_number'\n",
    "    region_name = 'r_name'\n",
    "\n",
    "    pmaps_4d = image.resample_img(\n",
    "        image.load_img(JULICH_ATLAS_PATH), mni_t1_4mm.affine, interpolation='nearest'\n",
    "    )\n",
    "\n",
    "    brain_regions_prob = []\n",
    "    prob_region_data = pmaps_4d.dataobj\n",
    "    non_zero = np.nonzero(pmaps_4d.dataobj)\n",
    "    for x, y, z, r in zip(*non_zero):\n",
    "        p = prob_region_data[x, y, z, r]\n",
    "        d = (p, x, y, z, r)\n",
    "        brain_regions_prob.append(d)\n",
    "\n",
    "else:\n",
    "    difumo_components = 256\n",
    "    brain_regions_prob = pd.read_hdf('./atlas_difumo.hdf', key=f'data_{difumo_components}')[['weights', 'i', 'j', 'k', 'component']]\n",
    "    regions = pd.read_hdf('./atlas_difumo.hdf', key=f'labels_{difumo_components}')\n",
    "    region_number = 'Component'\n",
    "    region_name = 'Difumo_names'\n",
    "\n",
    "\n",
    "\n",
    "# IBC data\n",
    "ibc = pd.read_csv(PEAKS_PATH)\n",
    "ibc = ibc[ibc['Cluster Size (mm3)'] > 20]\n",
    "\n",
    "ibc = ibc[['subject_id', 'img_id', 'X', 'Y', 'Z', 'Peak Stat', 'Cluster Size (mm3)']]\n",
    "\n",
    "ijk_positions = (\n",
    "    nib.affines.apply_affine(\n",
    "        np.linalg.inv(mni_t1_4mm.affine),\n",
    "        ibc[['X', 'Y', 'Z']]\n",
    "    ).astype(int)\n",
    ")\n",
    "ibc['i'] = ijk_positions[:, 0]\n",
    "ibc['j'] = ijk_positions[:, 1]\n",
    "ibc['k'] = ijk_positions[:, 2]\n",
    "\n",
    "ibc = ibc[['subject_id', 'img_id', 'i', 'j', 'k', 'Peak Stat', 'Cluster Size (mm3)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = './results/min_sample_difumo_1fold_out/'\n",
    " \n",
    "df = pd.DataFrame([])\n",
    "for filename in os.listdir(directory):\n",
    "    path = directory + filename\n",
    "    if os.path.isfile(path):\n",
    "        temp = pd.read_hdf(path)\n",
    "        df = pd.concat((df, temp))\n",
    "\n",
    "df = df.sort_values(['region', 'fold'])\n",
    "\n",
    "f_term = pd.read_hdf('./term2cp.hdf')\n",
    "\n",
    "df = df.join(f_term.set_index('t'), on='term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>fold</th>\n",
       "      <th>region</th>\n",
       "      <th>p</th>\n",
       "      <th>pn</th>\n",
       "      <th>bf</th>\n",
       "      <th>cp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>action perception</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.019628</td>\n",
       "      <td>0.098973</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>animacy decision</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009678</td>\n",
       "      <td>0.034236</td>\n",
       "      <td>0.282703</td>\n",
       "      <td>Reasoning and Decision Making</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>animacy perception</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009678</td>\n",
       "      <td>0.034236</td>\n",
       "      <td>0.282703</td>\n",
       "      <td>Perception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audiovisual perception</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.019628</td>\n",
       "      <td>0.098973</td>\n",
       "      <td>Perception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>auditory arithmetic processing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015365</td>\n",
       "      <td>0.010979</td>\n",
       "      <td>1.399510</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             term  fold  region         p        pn        bf  \\\n",
       "0               action perception     0       1  0.001943  0.019628  0.098973   \n",
       "1                animacy decision     0       1  0.009678  0.034236  0.282703   \n",
       "2              animacy perception     0       1  0.009678  0.034236  0.282703   \n",
       "3          audiovisual perception     0       1  0.001943  0.019628  0.098973   \n",
       "4  auditory arithmetic processing     0       1  0.015365  0.010979  1.399510   \n",
       "\n",
       "                              cp  \n",
       "0                                 \n",
       "1  Reasoning and Decision Making  \n",
       "2                     Perception  \n",
       "3                     Perception  \n",
       "4                                 "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>region</th>\n",
       "      <th>cp</th>\n",
       "      <th>p</th>\n",
       "      <th>pn</th>\n",
       "      <th>bf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>action perception</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.019472</td>\n",
       "      <td>0.099910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>action perception</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0.002178</td>\n",
       "      <td>0.019909</td>\n",
       "      <td>0.109422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>action perception</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0.017472</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>1.102308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>action perception</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>0.008432</td>\n",
       "      <td>0.017298</td>\n",
       "      <td>0.487550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>action perception</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>0.018322</td>\n",
       "      <td>0.015844</td>\n",
       "      <td>1.156595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                term  region cp         p        pn        bf\n",
       "0  action perception       1     0.001945  0.019472  0.099910\n",
       "1  action perception       2     0.002178  0.019909  0.109422\n",
       "2  action perception       4     0.017472  0.015854  1.102308\n",
       "3  action perception       6     0.008432  0.017298  0.487550\n",
       "4  action perception       8     0.018322  0.015844  1.156595"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probtr = df.groupby(['term', 'region','cp']).mean().drop('fold', axis=1).reset_index()\n",
    "probtr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = NeurolangPDL()\n",
    "\n",
    "j_brain = nl.add_tuple_set(\n",
    "    #(prob, i, j, k, region)\n",
    "    brain_regions_prob,\n",
    "    name='julich_brain'\n",
    ")\n",
    "\n",
    "dataIBC = nl.add_tuple_set(\n",
    "    #(subject, img, i, j, k, peak_stat, cluster_size)\n",
    "    ibc,\n",
    "    name='dataIBC'\n",
    ")\n",
    "\n",
    "ptr = nl.add_tuple_set(\n",
    "    #(term, region, cp, p, bf)\n",
    "    probtr,\n",
    "    name='prob_term_region'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoConstantPredicateFoundError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/frontend/probabilistic_frontend.py\u001b[0m in \u001b[0;36m_execute_query\u001b[0;34m(self, head, predicate)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                 goal, magic_rules = magic_rewrite(\n\u001b[0m\u001b[1;32m    349\u001b[0m                     \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsequent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogram_ir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/datalog/magic_sets.py\u001b[0m in \u001b[0;36mmagic_rewrite\u001b[0;34m(query, datalog)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# No constants present in the code, magic sets is not usefull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         raise NoConstantPredicateFoundError(\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;34m\"No predicate with constant argument found.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoConstantPredicateFoundError\u001b[0m: No predicate with constant argument found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j5/8y171yt540gbxr_gkpzm1fh80000gn/T/ipykernel_77717/3693547026.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     )'''\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplement_regions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplement\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_pandas_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/frontend/query_resolution_datalog.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"query takes 1 or 2 arguments\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0msolution_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctor_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/frontend/probabilistic_frontend.py\u001b[0m in \u001b[0;36m_execute_query\u001b[0;34m(self, head, predicate)\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0mquery_pred_symb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsequent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mInvalidMagicSetError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnsupportedProgramError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/frontend/probabilistic_frontend.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mprob_idb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"probabilistic\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mpostprob_idb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post_probabilistic\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_deterministic_stratum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdet_idb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprob_idb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformulas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_probabilistic_stratum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_idb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/frontend/probabilistic_frontend.py\u001b[0m in \u001b[0;36m_solve_deterministic_stratum\u001b[0;34m(self, det_idb)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_program_rewritten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdet_idb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mchase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchase_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogram_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdet_idb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_chase_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/datalog/chase/general.py\u001b[0m in \u001b[0;36mbuild_chase_solution\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0;34mf\"for rules {stratum}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             )\n\u001b[0;32m--> 563\u001b[0;31m             instance = chase_instance.execute_chase(\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0mstratum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_update\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             )\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/datalog/chase/general.py\u001b[0m in \u001b[0;36mexecute_chase\u001b[0;34m(self, rules, instance_update, instance)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mlog_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Evaluating rule %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m                 instance_update = instance_update | self.chase_step(\n\u001b[0m\u001b[1;32m    448\u001b[0m                     \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestriction_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstance_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                 )\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/datalog/chase/relational_algebra.py\u001b[0m in \u001b[0;36mchase_step\u001b[0;34m(self, instance, rule, restriction_instance)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mpredicates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantecedent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             substitutions = self.obtain_substitutions(\n\u001b[0m\u001b[1;32m    177\u001b[0m                 \u001b[0mpredicates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestriction_instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             )\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/datalog/chase/relational_algebra.py\u001b[0m in \u001b[0;36mobtain_substitutions\u001b[0;34m(self, rule_predicates_iterator, instance, restriction_instance)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'About to execute RA query %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mra_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRelationalAlgebraSolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mra_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mresult_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/expression_walker.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/expression_pattern_matching.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t\\tpattern: %(pattern)s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'pattern'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t\\tguard: %(guard)s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'guard'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mresult_expression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m                 LOG.info(\n\u001b[1;32m    312\u001b[0m                     \u001b[0;34m'\\t\\tresult: %(result_expression)s'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/expression_walker.py\u001b[0m in \u001b[0;36mprocess_expression\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                 \u001b[0mnew_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m                 \u001b[0mchanged\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mnew_arg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             elif (\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/expression_walker.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/expression_pattern_matching.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t\\tpattern: %(pattern)s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'pattern'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t\\tguard: %(guard)s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'guard'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mresult_expression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m                 LOG.info(\n\u001b[1;32m    312\u001b[0m                     \u001b[0;34m'\\t\\tresult: %(result_expression)s'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/expression_walker.py\u001b[0m in \u001b[0;36mprocess_expression\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchanged\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mnew_expression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_expression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/expression_walker.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/expression_pattern_matching.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t\\tpattern: %(pattern)s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'pattern'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t\\tguard: %(guard)s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'guard'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mresult_expression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m                 LOG.info(\n\u001b[1;32m    312\u001b[0m                     \u001b[0;34m'\\t\\tresult: %(result_expression)s'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/relational_algebra/relational_algebra.py\u001b[0m in \u001b[0;36mra_naturaljoin\u001b[0;34m(self, naturaljoin)\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaturaljoin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelation_left\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaturaljoin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelation_right\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaturaljoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0mrow_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_join_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnaturaljoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/utils/relational_algebra_set/pandas.py\u001b[0m in \u001b[0;36mnaturaljoin\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_product\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         new_columns = self.columns + tuple(\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/utils/relational_algebra_set/pandas.py\u001b[0m in \u001b[0;36mcross_product\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mleft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmpcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmpcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m             \u001b[0mnew_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmpcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mnew_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmpcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             new_container.columns = tuple(self._container.columns) + tuple(\n",
      "\u001b[0;32m~/opt/miniconda3/envs/neurolang/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     )\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/neurolang/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indicator_post_merge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_add_join_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_restore_index_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/neurolang/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_add_join_keys\u001b[0;34m(self, result, left_indexer, right_indexer)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mleft_has_missing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                             \u001b[0mleft_has_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mleft_indexer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mleft_has_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_terms = {}\n",
    "final_probs = {}\n",
    "\n",
    "import os\n",
    "directory = './results/min_sample_difumo_1fold_out/'\n",
    " \n",
    "df = pd.DataFrame([])\n",
    "for filename in os.listdir(directory):\n",
    "    path = directory + filename\n",
    "    if os.path.isfile(path):\n",
    "        temp = pd.read_hdf(path)\n",
    "        df = pd.concat((df, temp))\n",
    "\n",
    "df = df.sort_values(['region', 'fold'])\n",
    "\n",
    "f_term = pd.read_hdf('./term2cp.hdf')\n",
    "\n",
    "df = df.join(f_term.set_index('t'), on='term')\n",
    "\n",
    "validation_images = pd.read_csv('./removed_min_img.csv')\n",
    "for img in validation_images.img_id.values[:5]:\n",
    "    final_probs = {}\n",
    "    for term in df.term.unique():\n",
    "        if julich:\n",
    "            aud_sen = df[df.term == term].groupby('region').mean().join(regions.set_index(region_number)).reset_index()[['region', region_name, 'hemis', 'p', 'pn', 'bf']]\n",
    "        else:\n",
    "            aud_sen = df[df.term == term].groupby('region').mean().join(regions.set_index(region_number)).reset_index()[['region', region_name, 'p', 'pn', 'bf']]\n",
    "        res_image = res[res.image == img]\n",
    "        joined = aud_sen[['region', 'p']].set_index('region').join(res_image.set_index('region'), lsuffix='_term').fillna(0)\n",
    "        joined['prob'] = joined['p_term'] * joined['p']\n",
    "        term_prob = joined.prob.sum()\n",
    "        final_probs[term] = term_prob\n",
    "\n",
    "    image_terms[img] = final_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf = pd.DataFrame([])\n",
    "\n",
    "ibc_tag = pd.read_csv(PEAKS_PATH)\n",
    "ibc_tag = ibc_tag[ibc_tag['Cluster Size (mm3)'] > 20]\n",
    "\n",
    "for image, terms_probs in image_terms.items():\n",
    "    tmpdf = pd.DataFrame(terms_probs.items(), columns=['term', 'prob'])\n",
    "    tmpdf['img_id'] = image\n",
    "    tags = ibc_tag[ibc_tag.img_id == image].tag.unique()\n",
    "    if len(tags) == 1:\n",
    "        tmpdf['ibc_tags'] = tags[0]\n",
    "    else:\n",
    "        print(f'Error tag in {image}')\n",
    "    resdf = pd.concat((resdf, tmpdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367372\n",
      "action perception,  audiovisual perception, auditory scene analysis, social cognition\n",
      "[['response execution' 4.4930070270248725]\n",
      " ['response selection' 5.485083612892996]\n",
      " ['auditory perception' 13.216631965931347]\n",
      " ['working memory' 13.401458586773584]\n",
      " ['reading' 19.416595746852863]\n",
      " ['sentence processing' 24.169352466593136]\n",
      " ['visual face recognition' 28.89443547744922]\n",
      " ['spatial working memory' 31.142431312165073]\n",
      " ['visual word recognition' 31.64488033667359]\n",
      " ['theory of mind' 32.53603741919091]]\n",
      "\n",
      "367689\n",
      "speech perception,  speech processing,  language comprehension,  language processing,  action perception,  audiovisual perception,  auditory scene analysis,  social cognition\n",
      "[['response execution' 3.8236037907270024]\n",
      " ['response selection' 4.649465007639732]\n",
      " ['working memory' 11.520049476495455]\n",
      " ['auditory perception' 12.315333334590589]\n",
      " ['reading' 16.570040796753815]\n",
      " ['sentence processing' 21.839747435383984]\n",
      " ['visual face recognition' 24.69425848360634]\n",
      " ['feature comparison' 28.194559733364258]\n",
      " ['spatial working memory' 28.699354000284714]\n",
      " ['visual word recognition' 29.487428584920742]]\n",
      "\n",
      "365197\n",
      "speech perception,  speech processing,  language comprehension,  language processing,  action perception,  audiovisual perception,  auditory scene analysis,  social cognition\n",
      "[['response execution' 3.7426717473504665]\n",
      " ['response selection' 4.556449157160795]\n",
      " ['working memory' 11.259487077795416]\n",
      " ['auditory perception' 11.663771708873046]\n",
      " ['reading' 16.18686019325579]\n",
      " ['sentence processing' 21.085821098114977]\n",
      " ['visual face recognition' 24.058715248928422]\n",
      " ['spatial working memory' 27.133664109162993]\n",
      " ['feature comparison' 27.813473476435632]\n",
      " ['visual word recognition' 28.276221839789343]]\n",
      "\n",
      "369745\n",
      "speech perception,  speech processing,  language comprehension,  language processing,  action perception,  audiovisual perception,  auditory scene analysis,  social cognition\n",
      "[['response execution' 4.437087411658739]\n",
      " ['response selection' 5.40492648417229]\n",
      " ['auditory perception' 13.287860025695412]\n",
      " ['working memory' 13.304581027736374]\n",
      " ['reading' 19.27199915967173]\n",
      " ['sentence processing' 24.32688253549454]\n",
      " ['visual face recognition' 28.367354564976452]\n",
      " ['spatial working memory' 30.90421889807614]\n",
      " ['visual word recognition' 32.08294956534449]\n",
      " ['feature comparison' 32.37699191353066]]\n",
      "\n",
      "370059\n",
      "speech perception,  speech processing,  language comprehension,  language processing,  action perception,  audiovisual perception,  auditory scene analysis,  social cognition\n",
      "[['response execution' 2.954072000606441]\n",
      " ['response selection' 3.6056861924247956]\n",
      " ['auditory perception' 8.752750201096042]\n",
      " ['working memory' 9.009540008655522]\n",
      " ['reading' 12.717567758336187]\n",
      " ['sentence processing' 16.703029369423703]\n",
      " ['visual face recognition' 19.419724747001048]\n",
      " ['spatial working memory' 20.028219064214788]\n",
      " ['feature comparison' 21.761718786703796]\n",
      " ['visual word recognition' 22.605899805517357]]\n",
      "\n",
      "368974\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j5/8y171yt540gbxr_gkpzm1fh80000gn/T/ipykernel_77717/2371251783.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrmpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mibc_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'term'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "\n",
    "for img in validation_images.img_id.values:\n",
    "    rmpdf = resdf[resdf.img_id == img].sort_values('prob', ascending=True)\n",
    "    print(img)\n",
    "    print(rmpdf.ibc_tags.values[0])\n",
    "    print(rmpdf.head(10)[['term', 'prob']].values)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mono-Multi Modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn\n",
    "from nilearn import datasets, image, plotting\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RESAMPLE = 1\n",
    "\n",
    "mni_t1 = nib.load(datasets.fetch_icbm152_2009()['t1'])\n",
    "mni_t1_4mm = image.resample_img(mni_t1, np.eye(3) * RESAMPLE)\n",
    "\n",
    "def get_difumo_img(mask, n_components=256, out_dir='./difumo', resolution='3mm'):\n",
    "\n",
    "    DIFUMO_N_COMPONENTS_TO_DOWNLOAD_ID = {\n",
    "        64: 'pqu9r',\n",
    "        128: 'wjvd5',\n",
    "        256: '3vrct',\n",
    "        512: '9b76y',\n",
    "        1024: '34792',\n",
    "        }\n",
    "\n",
    "    download_id = DIFUMO_N_COMPONENTS_TO_DOWNLOAD_ID[n_components]\n",
    "    url = f\"https://osf.io/{download_id}/download\"\n",
    "    csv_file = os.path.join(\n",
    "        str(n_components), f\"labels_{n_components}_dictionary.csv\"\n",
    "    )\n",
    "    nifti_file = os.path.join(str(n_components), \"%s/maps.nii.gz\"%resolution)\n",
    "    files = [\n",
    "        (csv_file, url, {\"uncompress\": True}),\n",
    "        (nifti_file, url, {\"uncompress\": True}),\n",
    "    ]\n",
    "    files = nilearn.datasets.utils._fetch_files(out_dir, files, verbose=2)\n",
    "    labels = pd.read_csv(files[0])\n",
    "    img = nilearn.image.load_img(files[1])\n",
    "    img = nilearn.image.resample_to_img(\n",
    "        img,\n",
    "        target_img=mask,\n",
    "        interpolation=\"nearest\",\n",
    "    )\n",
    "\n",
    "    return img, labels\n",
    "\n",
    "difumo_img, difumo_labels = get_difumo_img(mni_t1_4mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = './results/min_sample_difumo_1fold_out/'\n",
    " \n",
    "df = pd.DataFrame([])\n",
    "for filename in os.listdir(directory):\n",
    "    path = directory + filename\n",
    "    if os.path.isfile(path):\n",
    "        temp = pd.read_hdf(path)\n",
    "        df = pd.concat((df, temp))\n",
    "\n",
    "df = df.sort_values(['region', 'fold'])\n",
    "\n",
    "f_term = pd.read_hdf('./term2cp.hdf')\n",
    "\n",
    "df = df.join(f_term.set_index('t'), on='term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_MIP(image, axis=0):\n",
    "    data = image.get_fdata()\n",
    "    ndata = np.maximum.reduce(data, axis=axis)\n",
    "    img = nib.Nifti1Image(ndata, image.affine)\n",
    "\n",
    "    return img\n",
    "\n",
    "def calc_argMIP(image, axis=0):\n",
    "    data = image.get_fdata()\n",
    "    ndata = data.argmax(axis=axis)\n",
    "    img = nib.Nifti1Image(ndata, image.affine)\n",
    "\n",
    "    return img\n",
    "\n",
    "pmaps_3d = calc_argMIP(difumo_img, axis=3)\n",
    "plotting.plot_img(pmaps_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pmaps_3d.get_fdata()\n",
    "\n",
    "non_zero = np.nonzero(data3)\n",
    "rmap = np.zeros_like(data3)\n",
    "\n",
    "dfterm = df[df.term == 'short term memory'].groupby('region').mean().reset_index()[['region', 'bf']]\n",
    "dict_bfs = dict(zip(dfterm.region, dfterm.bf))\n",
    "\n",
    "for x, y, z in zip(*non_zero):\n",
    "    reg = int(data3[x, y, z])\n",
    "    if reg in dict_bfs:\n",
    "        rmap[x, y, z] = dict_bfs[reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nl.scope as e:\n",
    "\n",
    "\n",
    "    '''e.reg_prob[e.region, e.image, e.PROB[e.region, e.image]] = (\n",
    "        (\n",
    "            e.julich_brain[..., e.i, e.j, e.k, e.region]\n",
    "        ) // (\n",
    "            e.dataIBC[..., e.image, e.i, e.j, e.k, ..., ...]\n",
    "        )\n",
    "    )'''\n",
    "\n",
    "    e.complement_regions[e.region, e.complement] = (\n",
    "        e.prob_term_region[..., e.region, ..., ..., ...] &\n",
    "        e.prob_term_region[..., e.complement, ..., ..., ...] &\n",
    "        (e.complement != e.region)\n",
    "    )\n",
    "\n",
    "    '''e.complement_prob[e.term, e.prod(e.inv_region)] = (\n",
    "        e.prob_term_region[e.term, e.region, e.topconcept, e.p, e.pn] &\n",
    "        (e.inv_region = )\n",
    "    )\n",
    "\n",
    "    e.decoding[e.term, e.region] = (\n",
    "        e.reg_prob[e.region, e.image, e.prob_region]\n",
    "    )'''\n",
    "            \n",
    "    res = nl.query((e.region, e.complement), e.complement_regions[e.region, e.complement])\n",
    "    res = res.as_pandas_dataframe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('neurolang')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a597b38520dcdbe9804bd6cc5a3070cdcfc67e2aa1859ba63fa8453f7a9dee3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
