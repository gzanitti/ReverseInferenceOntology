{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from nilearn import datasets, image, plotting\n",
    "from neurolang.frontend import NeurolangPDL\n",
    "\n",
    "import neurolang\n",
    "neurolang.config.disable_expression_type_printing()\n",
    "\n",
    "JULICH_REGIONS_PATH = 'JULICH_BRAIN_CYTOARCHITECTONIC_MAPS_2_9_MNI152_2009C_NONL_ASYM.txt'\n",
    "JULICH_ATLAS_PATH = 'JULICH_BRAIN_CYTOARCHITECTONIC_MAPS_2_9_MNI152_2009C_NONL_ASYM.pmaps.nii.gz'\n",
    "PEAKS_PATH = 'peaks_IBC.csv'\n",
    "\n",
    "julich = False\n",
    "RESAMPLE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mni_t1 = nib.load(datasets.fetch_icbm152_2009()['t1'])\n",
    "mni_t1_4mm = image.resample_img(mni_t1, np.eye(3) * RESAMPLE)\n",
    "\n",
    "if julich:\n",
    "\n",
    "    lines = []\n",
    "    with open(JULICH_REGIONS_PATH) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    count = 0\n",
    "    res = []\n",
    "    for line in lines:\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "            continue\n",
    "        splited = line.split(' ')\n",
    "        res.append((splited[0], ' '.join(splited[1:-1])[1:], splited[-1][:-2]))\n",
    "\n",
    "    regions = pd.DataFrame(res, columns=['r_number', 'r_name', 'hemis'])\n",
    "    regions = regions[~regions.r_name.str.contains('GapMap')]\n",
    "    regions = regions.astype({'r_number': 'int64'})\n",
    "    region_number = 'r_number'\n",
    "    region_name = 'r_name'\n",
    "\n",
    "    pmaps_4d = image.resample_img(\n",
    "        image.load_img(JULICH_ATLAS_PATH), mni_t1_4mm.affine, interpolation='nearest'\n",
    "    )\n",
    "\n",
    "    brain_regions_prob = []\n",
    "    prob_region_data = pmaps_4d.dataobj\n",
    "    non_zero = np.nonzero(pmaps_4d.dataobj)\n",
    "    for x, y, z, r in zip(*non_zero):\n",
    "        p = prob_region_data[x, y, z, r]\n",
    "        d = (p, x, y, z, r)\n",
    "        brain_regions_prob.append(d)\n",
    "\n",
    "else:\n",
    "    difumo_components = 256\n",
    "    brain_regions_prob = pd.read_hdf('./atlas_difumo.hdf', key=f'data_{difumo_components}')[['weights', 'i', 'j', 'k', 'component']]\n",
    "    regions = pd.read_hdf('./atlas_difumo.hdf', key=f'labels_{difumo_components}')\n",
    "    region_number = 'Component'\n",
    "    region_name = 'Difumo_names'\n",
    "\n",
    "\n",
    "\n",
    "# IBC data\n",
    "ibc = pd.read_csv(PEAKS_PATH)\n",
    "ibc = ibc[ibc['Cluster Size (mm3)'] > 20]\n",
    "\n",
    "ibc = ibc[['subject_id', 'img_id', 'X', 'Y', 'Z', 'Peak Stat', 'Cluster Size (mm3)']]\n",
    "\n",
    "ijk_positions = (\n",
    "    nib.affines.apply_affine(\n",
    "        np.linalg.inv(mni_t1_4mm.affine),\n",
    "        ibc[['X', 'Y', 'Z']]\n",
    "    ).astype(int)\n",
    ")\n",
    "ibc['i'] = ijk_positions[:, 0]\n",
    "ibc['j'] = ijk_positions[:, 1]\n",
    "ibc['k'] = ijk_positions[:, 2]\n",
    "\n",
    "ibc = ibc[['subject_id', 'img_id', 'i', 'j', 'k', 'Peak Stat', 'Cluster Size (mm3)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = './results/min_sample_difumo_1fold_out/'\n",
    " \n",
    "df = pd.DataFrame([])\n",
    "for filename in os.listdir(directory):\n",
    "    path = directory + filename\n",
    "    if os.path.isfile(path):\n",
    "        temp = pd.read_hdf(path)\n",
    "        df = pd.concat((df, temp))\n",
    "\n",
    "df = df.sort_values(['region', 'fold'])\n",
    "\n",
    "f_term = pd.read_hdf('./term2cp.hdf')\n",
    "\n",
    "df = df.join(f_term.set_index('t'), on='term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probtr = df.groupby(['term', 'region','cp']).mean().drop('fold', axis=1).reset_index()\n",
    "probtr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = NeurolangPDL()\n",
    "\n",
    "j_brain = nl.add_tuple_set(\n",
    "    #(prob, i, j, k, region)\n",
    "    brain_regions_prob,\n",
    "    name='julich_brain'\n",
    ")\n",
    "\n",
    "dataIBC = nl.add_tuple_set(\n",
    "    #(subject, img, i, j, k, peak_stat, cluster_size)\n",
    "    ibc,\n",
    "    name='dataIBC'\n",
    ")\n",
    "\n",
    "ptr = nl.add_tuple_set(\n",
    "    #(term, region, cp, p, bf)\n",
    "    probtr,\n",
    "    name='prob_term_region'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nl.scope as e:\n",
    "\n",
    "\n",
    "    e.reg_prob[e.region, e.image, e.PROB[e.region, e.image]] = (\n",
    "        (\n",
    "            e.julich_brain[..., e.i, e.j, e.k, e.region]\n",
    "        ) // (\n",
    "            e.dataIBC[..., e.image, e.i, e.j, e.k, ..., ...]\n",
    "        )\n",
    "    )\n",
    "            \n",
    "    res = nl.query((e.region, e.image, e.p), e.reg_prob[e.region, e.image, e.p])\n",
    "    res = res.as_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_terms = {}\n",
    "final_probs = {}\n",
    "\n",
    "import os\n",
    "directory = './results/min_sample_difumo_1fold_out/'\n",
    " \n",
    "df = pd.DataFrame([])\n",
    "for filename in os.listdir(directory):\n",
    "    path = directory + filename\n",
    "    if os.path.isfile(path):\n",
    "        temp = pd.read_hdf(path)\n",
    "        df = pd.concat((df, temp))\n",
    "\n",
    "df = df.sort_values(['region', 'fold'])\n",
    "\n",
    "f_term = pd.read_hdf('./term2cp.hdf')\n",
    "\n",
    "df = df.join(f_term.set_index('t'), on='term')\n",
    "\n",
    "validation_images = pd.read_csv('./removed_min_img.csv')\n",
    "for img in validation_images.img_id.values[:5]:\n",
    "    final_probs = {}\n",
    "    for term in df.term.unique():\n",
    "        if julich:\n",
    "            aud_sen = df[df.term == term].groupby('region').mean().join(regions.set_index(region_number)).reset_index()[['region', region_name, 'hemis', 'p', 'pn', 'bf']]\n",
    "        else:\n",
    "            aud_sen = df[df.term == term].groupby('region').mean().join(regions.set_index(region_number)).reset_index()[['region', region_name, 'p', 'pn', 'bf']]\n",
    "        res_image = res[res.image == img]\n",
    "        joined = aud_sen[['region', 'p']].set_index('region').join(res_image.set_index('region'), lsuffix='_term').fillna(0)\n",
    "        joined['prob'] = joined['p_term'] * joined['p']\n",
    "        term_prob = joined.prob.sum()\n",
    "        final_probs[term] = term_prob\n",
    "\n",
    "    image_terms[img] = final_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf = pd.DataFrame([])\n",
    "\n",
    "ibc_tag = pd.read_csv(PEAKS_PATH)\n",
    "ibc_tag = ibc_tag[ibc_tag['Cluster Size (mm3)'] > 20]\n",
    "\n",
    "for image, terms_probs in image_terms.items():\n",
    "    tmpdf = pd.DataFrame(terms_probs.items(), columns=['term', 'prob'])\n",
    "    tmpdf['img_id'] = image\n",
    "    tags = ibc_tag[ibc_tag.img_id == image].tag.unique()\n",
    "    if len(tags) == 1:\n",
    "        tmpdf['ibc_tags'] = tags[0]\n",
    "    else:\n",
    "        print(f'Error tag in {image}')\n",
    "    resdf = pd.concat((resdf, tmpdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367372\n",
      "action perception,  audiovisual perception, auditory scene analysis, social cognition\n",
      "[['response execution' 0.6634953040994305]\n",
      " ['response selection' 0.5192115167361702]\n",
      " ['working memory' 0.22053315621910932]\n",
      " ['auditory perception' 0.18885908937763282]\n",
      " ['reading' 0.1281919174767431]\n",
      " ['sentence processing' 0.12054611722627948]\n",
      " ['visual face recognition' 0.10115058898971024]\n",
      " ['visual word recognition' 0.08637337081677804]\n",
      " ['spatial working memory' 0.08273186239557836]\n",
      " ['feature comparison' 0.07432724314811825]]\n",
      "\n",
      "367689\n",
      "speech perception,  speech processing,  language comprehension,  language processing,  action perception,  audiovisual perception,  auditory scene analysis,  social cognition\n",
      "[['response execution' 0.5291609958571543]\n",
      " ['response selection' 0.40004564547459764]\n",
      " ['auditory perception' 0.23765584279995672]\n",
      " ['working memory' 0.1829003381047178]\n",
      " ['sentence processing' 0.12263578541488003]\n",
      " ['spatial working memory' 0.10176442932114191]\n",
      " ['reading' 0.09978068262054869]\n",
      " ['visual word recognition' 0.09859050314901947]\n",
      " ['visual face recognition' 0.08278372517277932]\n",
      " ['word maintenance' 0.07586373140660194]]\n",
      "\n",
      "365197\n",
      "speech perception,  speech processing,  language comprehension,  language processing,  action perception,  audiovisual perception,  auditory scene analysis,  social cognition\n",
      "[['response execution' 0.5227833952119314]\n",
      " ['response selection' 0.4008487719653897]\n",
      " ['auditory perception' 0.20583941919643028]\n",
      " ['working memory' 0.17757696940900114]\n",
      " ['sentence processing' 0.11512602310749177]\n",
      " ['reading' 0.09996063058196061]\n",
      " ['visual word recognition' 0.08896890672008656]\n",
      " ['spatial working memory' 0.088018647418488]\n",
      " ['visual face recognition' 0.07990744037135258]\n",
      " ['word maintenance' 0.06809067700910262]]\n",
      "\n",
      "369745\n",
      "speech perception,  speech processing,  language comprehension,  language processing,  action perception,  audiovisual perception,  auditory scene analysis,  social cognition\n",
      "[['response execution' 0.6466115050798993]\n",
      " ['response selection' 0.4999694092876956]\n",
      " ['working memory' 0.21587755674740802]\n",
      " ['auditory perception' 0.20333393697650726]\n",
      " ['reading' 0.12712888928541766]\n",
      " ['sentence processing' 0.1260715160383356]\n",
      " ['visual face recognition' 0.09609921180938671]\n",
      " ['visual word recognition' 0.09338009557402871]\n",
      " ['spatial working memory' 0.08686130139374885]\n",
      " ['word maintenance' 0.06901329052235172]]\n",
      "\n",
      "370059\n",
      "speech perception,  speech processing,  language comprehension,  language processing,  action perception,  audiovisual perception,  auditory scene analysis,  social cognition\n",
      "[['response execution' 0.4171228517964103]\n",
      " ['response selection' 0.32715859929957447]\n",
      " ['working memory' 0.1480792997965668]\n",
      " ['auditory perception' 0.12497309224644348]\n",
      " ['sentence processing' 0.09010781848757102]\n",
      " ['reading' 0.07629647150444213]\n",
      " ['visual word recognition' 0.07138713710767752]\n",
      " ['visual face recognition' 0.06958973483785552]\n",
      " ['theory of mind' 0.055457029741919475]\n",
      " ['word maintenance' 0.05327499815058283]]\n",
      "\n",
      "368974\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j5/8y171yt540gbxr_gkpzm1fh80000gn/T/ipykernel_77717/1649999105.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrmpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mibc_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'term'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "\n",
    "for img in validation_images.img_id.values:\n",
    "    rmpdf = resdf[resdf.img_id == img].sort_values('prob', ascending=False)\n",
    "    print(img)\n",
    "    print(rmpdf.ibc_tags.values[0])\n",
    "    print(rmpdf.head(10)[['term', 'prob']].values)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mono-Multi Modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn\n",
    "from nilearn import datasets, image, plotting\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RESAMPLE = 1\n",
    "\n",
    "mni_t1 = nib.load(datasets.fetch_icbm152_2009()['t1'])\n",
    "mni_t1_4mm = image.resample_img(mni_t1, np.eye(3) * RESAMPLE)\n",
    "\n",
    "def get_difumo_img(mask, n_components=256, out_dir='./difumo', resolution='3mm'):\n",
    "\n",
    "    DIFUMO_N_COMPONENTS_TO_DOWNLOAD_ID = {\n",
    "        64: 'pqu9r',\n",
    "        128: 'wjvd5',\n",
    "        256: '3vrct',\n",
    "        512: '9b76y',\n",
    "        1024: '34792',\n",
    "        }\n",
    "\n",
    "    download_id = DIFUMO_N_COMPONENTS_TO_DOWNLOAD_ID[n_components]\n",
    "    url = f\"https://osf.io/{download_id}/download\"\n",
    "    csv_file = os.path.join(\n",
    "        str(n_components), f\"labels_{n_components}_dictionary.csv\"\n",
    "    )\n",
    "    nifti_file = os.path.join(str(n_components), \"%s/maps.nii.gz\"%resolution)\n",
    "    files = [\n",
    "        (csv_file, url, {\"uncompress\": True}),\n",
    "        (nifti_file, url, {\"uncompress\": True}),\n",
    "    ]\n",
    "    files = nilearn.datasets.utils._fetch_files(out_dir, files, verbose=2)\n",
    "    labels = pd.read_csv(files[0])\n",
    "    img = nilearn.image.load_img(files[1])\n",
    "    img = nilearn.image.resample_to_img(\n",
    "        img,\n",
    "        target_img=mask,\n",
    "        interpolation=\"nearest\",\n",
    "    )\n",
    "\n",
    "    return img, labels\n",
    "\n",
    "difumo_img, difumo_labels = get_difumo_img(mni_t1_4mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = './results/min_sample_difumo_1fold_out/'\n",
    " \n",
    "df = pd.DataFrame([])\n",
    "for filename in os.listdir(directory):\n",
    "    path = directory + filename\n",
    "    if os.path.isfile(path):\n",
    "        temp = pd.read_hdf(path)\n",
    "        df = pd.concat((df, temp))\n",
    "\n",
    "df = df.sort_values(['region', 'fold'])\n",
    "\n",
    "f_term = pd.read_hdf('./term2cp.hdf')\n",
    "\n",
    "df = df.join(f_term.set_index('t'), on='term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_MIP(image, axis=0):\n",
    "    data = image.get_fdata()\n",
    "    ndata = np.maximum.reduce(data, axis=axis)\n",
    "    img = nib.Nifti1Image(ndata, image.affine)\n",
    "\n",
    "    return img\n",
    "\n",
    "def calc_argMIP(image, axis=0):\n",
    "    data = image.get_fdata()\n",
    "    ndata = data.argmax(axis=axis)\n",
    "    img = nib.Nifti1Image(ndata, image.affine)\n",
    "\n",
    "    return img\n",
    "\n",
    "pmaps_3d = calc_argMIP(difumo_img, axis=3)\n",
    "plotting.plot_img(pmaps_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pmaps_3d.get_fdata()\n",
    "\n",
    "non_zero = np.nonzero(data3)\n",
    "rmap = np.zeros_like(data3)\n",
    "\n",
    "dfterm = df[df.term == 'short term memory'].groupby('region').mean().reset_index()[['region', 'bf']]\n",
    "dict_bfs = dict(zip(dfterm.region, dfterm.bf))\n",
    "\n",
    "for x, y, z in zip(*non_zero):\n",
    "    reg = int(data3[x, y, z])\n",
    "    if reg in dict_bfs:\n",
    "        rmap[x, y, z] = dict_bfs[reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nl.scope as e:\n",
    "\n",
    "\n",
    "    '''e.reg_prob[e.region, e.image, e.PROB[e.region, e.image]] = (\n",
    "        (\n",
    "            e.julich_brain[..., e.i, e.j, e.k, e.region]\n",
    "        ) // (\n",
    "            e.dataIBC[..., e.image, e.i, e.j, e.k, ..., ...]\n",
    "        )\n",
    "    )'''\n",
    "\n",
    "    e.complement_regions[e.region, e.complement] = (\n",
    "        e.prob_term_region[..., e.region, ..., ..., ...] &\n",
    "        e.prob_term_region[..., e.complement, ..., ..., ...] &\n",
    "        (e.complement != e.region)\n",
    "    )\n",
    "\n",
    "    '''e.complement_prob[e.term, e.prod(e.inv_region)] = (\n",
    "        e.prob_term_region[e.term, e.region, e.topconcept, e.p, e.pn] &\n",
    "        (e.inv_region = )\n",
    "    )\n",
    "\n",
    "    e.decoding[e.term, e.region] = (\n",
    "        e.reg_prob[e.region, e.image, e.prob_region]\n",
    "    )'''\n",
    "            \n",
    "    res = nl.query((e.region, e.complement), e.complement_regions[e.region, e.complement])\n",
    "    res = res.as_pandas_dataframe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('neurolang')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a597b38520dcdbe9804bd6cc5a3070cdcfc67e2aa1859ba63fa8453f7a9dee3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
